---
title:    "Proyecto de Estancia de Investigación"
subtitle: "Modelos para la Construcción de Portafolios de Productos de Telefonía Celular"
author:  
  - "Ana Luisa Masetto Herrera - 000183203"
output: 
  pdf_document:
    number_sections: true
    toc_depth: 2
fontsize: 10pt
header-includes:
#  - \usepackage[spanish]{babel}
#  - \decimalpoint
#documentclass: "book"

---

\tableofcontents

\pagebreak

# Introducción

La industría de las telecomunicaciones ha crecido drásticamente en los últimos años dado a los diversos avances tecnológicos que se han alcanzado; dentro de esta industría se encuentra el sector enfocado a la telefonía celular, sector que también ha presenciado un aumento considerable en su demanda de productos. De acuerdo con información recopilada en conjunto por el Instituto Nacional de Estadística y Geografía (INEGI), la Secretaría de Comunicaciones y Transportes (SCT) y el Instituto Federal de Telecomunicaciones (IFT), el uso de la telefonía celular ha ganado lugar como una de las tecnologías con mayor penetración en la población mexicana, estimando que el año pasado había un total de 69.6 millones de personas que tenían un teléfono inteligente, indicando un incremento de usuarios del 7.57% en comparación con el 2017 (INEGI, 2018).   

En la actualidad se sabe que prácticamente todas las personas poseen un celular, no solamente para facilitar la comunicación entre amigos, familiares, compañeros de trabajo, clientes, etc; sino que también se ha convertido en una herramimenta que facilita algunas de las actividades cotidianas de las personas, como: buscar direcciones, pedir comida, solicitar información bancaria, realizar documentos para tareas o trabajos, o simplemente funciona como fuente de entretenimiento gracias a su capacidad para conectarse a redes sociales y para almacenar juegos, videos, fotos y música. 

Si bien dijo Oswaldo Contreras Saldívar, presidente del Instituto Federal de Telecomunicaciones (IFT), “No sólo se usa el dispositivo móvil por lo práctico, sino porque lo queremos usar para todo, todo el tiempo: lo queremos al alcance de la mano”, sin embargo, es muy importante resaltar que aunque la necesidad creciente de tener un dispositivo movil es de la mayoria de las personas, no todas buscan las mismas caracteristicas en los celulares. Hay personas que se fijan únicamente en el rango de precios (gamma del producto), en la marca, en la apariencia, pero también hay personas que se guían más por la construcción en si del modelo, como son la capacidad de memoria, la vida útil del producto, la definición de la cámara, el software que utiliza, etc. 
 
Es por eso que las compañías enfocadas a la venta de productos de telefonía celular enfrentan el reto de __pronosticar el número unidades a vender de cada producto__, de no hacerse propiamente esto podría generar problemas relacionados con la pérdida de clientes dado la falta de productos en los puntos de venta, o problemas como gastos adicionales en trasporte o almacenamiento. Esto se debe a que las compañias de este sector cuentan con diversos puntos de venta, en distintas ciudades, estados y zonas, y es muy probable que el mercado al que se dirigue cada uno de estos puntos no sea el mismo. 

Partiendo de esta situación, el proyecto descrito en este documento busca generar un proyecto de Ciencia de Datos utilizando información real de una empresa de telecomunicaciones en México y cuyo resultado final será la propuesta de modelos para la construcción de portafolios de telefonia celular. El proyecto fue realizado por Ana Luisa Masetto Herrera, alumna de la maestría de Ciencia de Datos en el Instituto Tecnológico Autónomo de México (ITAM); este se llevó acabo en las instalaciones de la empresa IBM México en Santa Fe y fue supervisado por el ingeniero Rubén Pineda Piña. Cabe mencionar que los datos utilizados para este proyecto son de un cliente de IBM, por lo tanto, y dado los contratos de privacidad que se tiene con los clientes de IBM, el nombre real la empresa a la que corresponden los datos no se va a mencionar explícitamente, es por eso que a partir de este momento se le referirá a dicha empresa como __la empresa ABCD__, con el fin de que esta permanezca en anonimato. 

\pagebreak

# Descripción del Proyecto

El objetivo general del proyecto es desarrollar un proyecto de ciencia de datos con el que se pueda mejorar la construcción de portafolios de productos de telefonía celular en diversos puntos de venta de la empresa ABCD. Aunado a este objetivo, se tienen diversos objetivos específicos: 

  1. Familiarice con la problemática a tratar, la empresa y las herramientas que IBM proporciona. 
  
  2. Analizar los datos crudos proporcionados por la empresa ABCD para detectar los problemas de calidad que estos presentan con el fin de llevar a cabo una limpieza de datos. 
  
  3. Realizar un análisis exploratorio de los datos para obtener información relevante que permita entender de mejor manera la situación actual de la empresa. 
  
  4. Proponer modelos de regresión que permitan cumplir con el objetivo principal del proyecto. 
  
  5. Realizar las transformaciones necesarias de los datos para facilitar su manejo. 
  
  6. Implementar ingeniería de características que permita enriquecer los modelos propuestos.
  
  7. Desarrollar diferentes modelos para comparar su comportamiento. 
  
  8. Seleccionar el modelo con el mejor desempeño. 
  
  9. Realizar la documentación necesaria para entregar al supervisor del proyecto. 
  
  10.	Realizar la documentación necesaria para entregar a la maestría de Ciencia de Datos en el ITAM. 
  
  

# Herramientas

Antes de indagar más en la problemática a tratar en este proyecto, es importante mencionar las herramientas que se utilizaron para cumplir con cada uno de los objetivos del proyecto. 

Lo primero que hay que mencionar es que todos los código se ejecutaron directamente de la plataforma de IBM utilizando __Watson Studio__; una plataforma en la nube que facilita el manejo de grandes volúmenes de datos y que además cuenta con diversas herramientas tales como: __RStudio__ y __Jupyter Notebook__. 

Una vez que ya se mencionó esa parte, es importante mencionar que para la parte de $limpieza$, $transformación$, $análisis$ $exploratorio$, e $ingeniería$ $de$ $características$, se utilizó __RStudio__ como entorno de desarrollo. 

Como siguiente punto, se utilizó __Jupyter Notebook__ para desarrollar los códigos para los modelos de aprendizaje de máquina. 

Finalmente, todos los códigos creados se subieron a la siguiente página de github \footnote{\url{https://github.com/AnaLuisaMasetto/Estancia_de_Investigacion} } donde pueden consultarse para futuras referencias. 









\pagebreak

# Descripción de las Bases de Datos

Para este proyecto se tienen datos reales de la empresa __ABCD__, compañía de la industría de las telecomunicaciones enfocada en el sector de telefonía celular. La empresa proporcionó dos bases de datos: la primera corresponde a un catálogo de tiendas y la segunda a un registro de ventas; ambas bases de datos se describen con más detalle a continuación. 
 
## Catálogo de Puntos de Venta
 
El catálogo fue proporcionado en un archivo con extensión __csv__ y tiene un total de 1,911 renglones y 79 columnas. Las 79 variables poseen diferentes propiedades relacionadas con los puntos de venta, sin embargo, de estas sólo se tomarán en cuenta las siguientes: 

  - \textbf{Variables a considerar del catálogo de tiendas:}
    - \textbf{Nombre del pdv}:        Nombre del punto de venta. 
    - \textbf{Nuevo nombre del pdv}:  Nuevo nombre del punto de venta (no todos los puntos de venta fueron renombrados). 
    - \textbf{Regiones homologadas}:  División por región a la que pertenece cada punto de venta (norte, sur, etc.). 
    - \textbf{Estado}:                Estado donde se encuentra el punto de venta. 
    - \textbf{Ciudad}:                Ciudad donde se encuentra el punto de venta. 
    - \textbf{Latitud}:               Ubicación con coordenadas geográficas del punto de venta. 
    - \textbf{Longitud}:              Ubicación con coordenadas geográficas del punto de venta.
 
Las razones por las cuales no se consideran las demás variables son: en primer lugar, no es claro a que se refieren algunas variables y no se proporcionó un diccionario con la descripción de ellas, en segundo lugar es porque existen muchos valores faltantes y la información para completarlos no es posible de obtener por cuenta propia y la empresa no accedió a proporcionar más información, por último, hay variables con información estimada (como población en el 2020) de la cuál no se sabe con certeza las unidades ni la forma en la que se calcularon. 
 
## Registro de Ventas

El segundo documento que se proporcionó fue el que contiene los registros de ventas de la empresa, registros que tienen lugar a partir del 1 de junio del 2018 al 31 de marzo del 2019. El archivo con extensión __csv__ con dicha información tiene 1,048,575 renglones y 10 columnas. 

Las 10 variables que se tienen son las siguientes: 

  - \textbf{Variables del registro de ventas:}
    - \textbf{Punto de Venta}:        Nombre del punto de venta donde se realizó la compra. 
    - \textbf{Plan tarifario}:        Plan tarifario bajo el cual se vendió la unidad. 
    - \textbf{Sku}:                   Código único del producto. Cabe mencionar que son códigos internos de la compañía, por lo tanto, no se sabe el nombre comercial de los productos. 
    - \textbf{Fecha}:                 Fecha en la que se registró la venta de la unidad. 
    - \textbf{Precio}:                Precio de la unidad. 
    - \textbf{Costo}:                 Costo de la unidad. Estos valores son muy cercanos a los de la variable anterior. 
    - \textbf{Marca}:                 Marca de la unidad vendida.
    - \textbf{Ventas}:                Columna con valores iguales a 1. Es decir, cada registro dentro del documento (cada renglón) corresponde a una venta. 
    - \textbf{Mth}:                   Mes en el que se hizo la venta de la unidad. 
    - \textbf{Yr}:                    Año en la que se hizo la venta de la unidad.

\pagebreak

# Limpieza y Transformación de los Datos

En esta sección del documento se describe cuáles fueron los problemas de calidad que se detectaron en ambos archivos (catálogo y registro) y cuál fue el proceso de limpieza y transformación que se llevó a cabo para llegar a una base de datos limpia que permita facilitar su manejo e interpretación. Este procesamiento de los datos se llevo a cabo en un script en RStudio que puede consultarse en esta liga \footnote{\url{https://github.com/AnaLuisaMasetto/Estancia_de_Investigacion/tree/master/Limpieza_De_Datos} }.

## Problemas de calidad: Catálogo de tiendas

  - \textbf{Máyusculas y minúsculas}: Había celdas con información en mayúsculas y otras en mínusculas. 
  - \textbf{Caracteres especiales}: Algunos de los registros tenían acentos, guiones y dobles espacios. 
  - \textbf{Valores faltantes}:
    - \textbf{}La columna __Nuevo nombre del pdv__ poseía muchos valores faltantes, al igual que las columnas de __longitud__ y __latitud__.
    
\begin{figure}[h]
\includegraphics{G1.jpg}
\centering
\caption{Valores faltantes dentro del cátalogo de tiendas proporcionado por la empresa ABCD.}
\end{figure}

  - \textbf{Tiendas faltantes en el catálogo}: Para detectar este problema se intento hacer un __join__ del registro con el catálogo y se detectaron algunas tiendas en el registro que no estaban en el catálogo. 
  - \textbf{Tiendas repetidas en el catálogo}: Habían tiendas registradas más de una vez en el catálogo.
  - \textbf{Registros erroneos}:
    - \textbf{}La columna de estados tenía más de 32 estados registrados y como la información es únicamente de la república mexicana, se sabe que eso no es posible.
    - \textbf{}La columna de las regiones tenía registros que no hacían sentido.
    - \textbf{}Por un lado, la columna de longitud tenía coordenadas registradas __positivas__ y eso no es posible dado que los estados de la república mexicana únicamente abarcan coordenadas de longitud entre -86 y -116 aproximadamente. Por el otro, la columna de latitud tenía coordanas registradas fuera de rango, por ejemplo: había un registro cuya latitud era de 20 millones, valores que no es posible. 

\begin{figure}[h]
\includegraphics{G2.jpg}
\centering
\caption{Resumen donde se notan los valores fuera de rango de las variables de latitud y longitud.}
\end{figure}


\pagebreak

## Problemas de calidad: Registro de ventas

  - \textbf{Mayúsculas y minúsculas}: No se tenía un formato definido en tanto a la forma en la que se debía de hacer los registros. Había celdas con información en mayúsculas y otras en mínusculas.
  - \textbf{Valores faltantes}:
    - \textbf{}La columna de __precio__ tenía más de 7,000 valores faltantes.
    - \textbf{}La columna de __marca__ tenía 9 valores faltantes. 
    - \textbf{}La columna de __costo__ tenía 7 valores faltantes. 

\begin{figure}[h]
\includegraphics{G3.jpg}
\centering
\end{figure}
    
\begin{figure}[h]
\includegraphics{G4.jpg}
\centering
\caption{Valores faltantes del Registro de Ventas.}
\end{figure}

  - \textbf{Formato no homogeneo en la columna de fecha}: Los registros de la columna de fecha tienen diferentes formatos (01-03-18, 01MAR18, 01-03-2018, entre otros). 
  - \textbf{Caracteres especiales}: Algunos de los registros tenían acentos, guiones y dobles espacios.
  - \textbf{Errores de registro}: Hay marcas escritas de diversas maneras. 
  - \textbf{Tiendas mal escritas}: Hay tiendas que están registradas con un nombre erróneo. 

## Limpieza de Datos: Catálogo de tiendas 

Una vez que se detectaron los problemas de calidad en el catálogo se procede con su limpieza. A continuación se presentan las actividades principales que se llevaron a cabo. 

  - \textbf{Homogeneizar todos los registros a minúsculas}: Todos los registros se convierten a minúsculas para facilitar su manejo. 
  - \textbf{Eliminar caracteres especiales}: Todos los acentos se remueven, al igual que la letra __ñ__, los dobles espacios y otros tipos de espacios (Non Breaking Spaces).
  - \textbf{Imputar valores faltantes}: 
    - \textbf{}Los puntos de venta que cambiaron de nombre fueron sustituidos por su nuevo nombre de tal manera que en lugar de trabajar con dos columnas únicamente se quedó una llamada __punto_de_venta___. 
    - \textbf{} Los valores faltantes en las columnas de __longitud__ y __latitud__ fueron imputados. Tras un proceso sumamente artesanal de buscar cada una de las 39 tiendas con valores faltantes en sus coordenas geograficas en google maps se logró recopilar la información faltante. 
  - \textbf{Correción de registros erroneos}:
    - \textbf{} Se homogenizan los registros de tal manera que solo se tenga información de los 32 estados de la repúbica mexicana. Por ejemplo, en la columna de estado estaba escrito __matamoros__ y este se sustituyó por __tamaulipas__, o el __estado de méxico__ estaba escrito de diferentes formas y este se homogeneizó. 
    - \textbf{} Los registros positivos dentro de la columna de __longitud__ se cambiaron a valores negativos y se verificaron de tal manera que estás fueran correctas y efectivamente se refirieran a algún punto de venta de la compañía ABCD. 
    - \textbf{} Los registros fuera de rango de la columna de __latitud__ se corrigieron a valores dentro de rango. 
    - \textbf{} Se buscó información sobre las zonas en las que se divide el territorio mexicano y se encontró en la página de CONABIO \footnote{\url{http://www.conabio.gob.mx/informacion/gis/layouts/recomgw.png} } que la república se puede dividir en 8 regiones, por lo tanto, se actualizan las regiones originales de la base de datos y se sustituyen por la nueva división. 

  - \textbf{Completar tiendas faltantes en el catálogo}: Se hizo un join con la base de datos de registro de ventas y se detectaron las tiendas que no hicieron match, luego estas se intentaron buscar dentro del catálogo con con otros nombres para ver si no era por un mal registro y las que no se encontraban se buscaron manualmente en google maps para luego agregarlas al catálogo. 
  
  - \textbf{Detectar tiendas repetidas en el catálogo}: Habían 26 tiendas que estaban registradas más de una vez en el catálogo, estas se analizaron para ver si su repetición era justificada o no. Por ejemplo, la tienda llamada __Chapultepec__ tenía 4 registros distintos, los cuales tenían distinta ubicación (zona, ciudad y estado), por ende, lo único que se debía de hacer era cambiar los nombres de los puntos de venta de tal manera que estas tiendas se pudieran identificar por separado, sin embargo, hubo casos en que la tienda se repetía con los mismos valores, por lo tanto, los registros extras se eliminaban. 

\begin{figure}[h]
\includegraphics{G5.jpg}
\centering
\caption{Ejemplo de tiendas repetidas a ser renombradas.}
\end{figure}

\pagebreak

\begin{figure}[h]
\includegraphics{G6.jpg}
\centering
\caption{Ejemplo de tiendas repetidas donde dos deben de ser eliminadas.}
\end{figure}


Tras esta limpieza se genera un nuevo catálogo con 2,783 puntos de venta distintos y cada uno de ellos con su información geográfica completa. 

\begin{figure}[h]
\includegraphics{G7.jpg}
\centering
\caption{Catálogo final.}
\end{figure}



## Limpieza de Datos: Registro de ventas

Una vez que se detectaron los problemas de calidad en el registro de ventas se procede con su limpieza. A continuación se presentan las actividades principales que se llevaron a cabo.

  - \textbf{Homogeneizar los registros a minúsculas}: Todos los registros se convierten a minúsculas para facilitar su manejo.
  - \textbf{Imputar valores faltantes}:
    - \textbf{}La columna de __precio__ tenía muchos valores faltantes, sin embargo, se habla con un experto de IBM en la industría de telecomunicaciones y se llega al acuerdo de únicamente utilizar una variable entre precio y costo dado que los valores de estas dos variables eran prácticamente los mismos, por ende, esta columna se descarta. 
    - \textbf{}La columna de __costo__ tenía 7 valores faltantes, los cuales se imputaron al buscar en los demás registros el sku de los productos con costos faltantes, luego se filtraron los resultados por punto de venta y fecha y al final se obtuvieron los valores a imputar.
    - \textbf{}La columna de __marca__ tenía 9 valores faltantes, los cuales se imputaron de manera similar al caso anterior, buscando el sku de los productos con valores faltantes en esta columna en los demás registros, y al ser el sku el código único del producto fue muy sencillo encontrar a cuál marca se referían. 
  - \textbf{Homogeneizar el formato de la fecha}: Todos los registros de fecha se homogeneizar de tal manera que todos fueran con el formato: AAAA-MM-DD
  - \textbf{Remover caracteres especiales}: Todos los acentos se remueven, al igual que la letra __ñ__, los dobles espacios y otros tipos de espacios (Non Breaking Spaces).
  - \textbf{Corregir tiendas mal escritas}: Hay tiendas que están registradas con un nombre erróneo, por lo tanto, se detectan estás tiendas y se les cambia el nombre al nombre correcto dentro del catálogo.
  - \textbf{Eliminar errores de registro}:
    - \textbf{}En un principio se tenían 32 marcas distintas en el registro de ventas, sin embargo, esto se debía a que las marcas estaban registradas de manera erronea ya que en lugar de considerar únicamente la marca, algunos registros tenían incluido el modelo del celular, por lo tanto, se seccionan las marcas únicamente en 12. 

\begin{figure}[h]
\includegraphics{G8.jpg}
\centering
\end{figure}

\begin{figure}[h]
\includegraphics{G9.jpg}
\centering
\caption{Errores de registro en la columna de Marca.}
\end{figure}

## Paso final de la limpieza

Como último paso para tener los datos limpios, se hace una fusión de ambas bases de datos para tener un archivo donde se tenga información relacionada con las ventas y con algunas características geográficas de los puntos de venta.  

El documento final tras la limpieza tiene 1,048,575 registros de ventas y 15 variables, las cuales son: 

- \textbf{Variables en el csv limpio:}
    - \textbf{Punto de venta}:        Nombre del punto de venta. 
    - \textbf{Plan tarifario}:        Plan tarifario al que pertenece la unidad vendida.
    - \textbf{Sku por equipo}:        Código único del producto vendido. Cabe mencionar que son códigos internos de la compañía ABCD, por lo tanto, no se sabe el nombre comercial de los productos.
    - \textbf{Fecha}:                 Fecha en la que se hizo la venta en formato AAAA-MM-DD.
    - \textbf{Costo}:                 Costo del producto. 
    - \textbf{Marca}:                 Marca del producto vendido (32 posibles valores). 
    - \textbf{Ventas}:                Columna con valores iguales a 1. Es decir, cada registro dentro del documento (cada renglón) corresponde a una venta.
    - \textbf{Mes}:                   Mes en el que se realizó la compra del producto. 
    - \textbf{Anio}:                  Año en el que se realizó la compra del producto. 
    - \textbf{Marca modificada}:      Marca del producto vendido después de la limpieza (12 valores posibles). 
    - \textbf{Estado}:                Estado en el que se hizo la venta. 
    - \textbf{Ciudad}:                Ciudad en la que se hizo la venta. 
    - \textbf{Latitud}:               Ubicación con coordenadas geográficas del punto de venta.
    - \textbf{Longitud}:              Ubicación con coordenadas geográficas del punto de venta.
    - \textbf{Zona}:                  Zona en la que se hizo la venta con la división establecida por CONABIO. 
    
## Transformación de los datos

Una vez que ya se tuvieron los datos limpios, hubo dos transformaciones adicionales que se tuvieron que hacer. Este proceso se llevo a cabo en un script en Rstudio que puede encontrarse en la siguiente liga\footnote{\url{https://github.com/AnaLuisaMasetto/Estancia_de_Investigacion/tree/master/Transformacion_De_Datos_E_Ingenieria_De_Caracteristicas} } . 

- \textbf{Costo promedio por producto:} Tras la limpieza de los datos, se observó que el costo de los productos cambiaba ligeramente en los diferentes periodos de venta (meses), por lo tanto, se optó por obtener el __costo promedio por producto__ y utilizar este valor para construir una nueva variable llamada __gamma__ con posibles valores: __premium__, __alta__, __media__ y __baja__. Esto se hace gracias que se tiene una reunión más con el experto de IBM con respecto a la industría de telecomunicaciones y se discute que para una empresa del sector de telefonía movíl, el tener bien definido a qué gamma pertenece cada producto es muy importante. 
  
\begin{figure}[h]
\includegraphics{G10.jpg}
\centering
\caption{Rango de valores de la variable de costo con sus respectivas gammas.}
\end{figure}

- \textbf{Agrupación:} Una vez que ya se tuvieron todos los campos limpios y homogeneizados, se procede a hacer una agrupación por __punto de venta, fecha, mes, anio, sku, marca, gamma, zona, estado, ciudad, latitud, longitud__, y después se suman el número de ventas que cumplen con las agrupaciones pasadas. Por ende, se pasa de tener un archivo con 1,048,575 renglones correspondientes a registros individuales, a un archivo con un total de 932,963 renglones correspondientes a registros agrupados. 


\pagebreak

# Análisis exploratorio de los datos

A continuación, se procede con el __Análisis Exploratorio de los Datos__ que busca extraer información relevante de los datos. A este punto del proyecto, ya se cuenta con un archivo limpio con un total de 932,963 observaciones y 13 variables, las cuales se van a analizar para extraer la mayor cantidad posible de información para determinar el escenario general en el que se encuentra la compañia __ABCD__. 

\begin{figure}[h]
\includegraphics{G11.jpg}
\centering
\caption{Variables de los datos limpios.}
\end{figure}

Para realizar este análisis fue necesario crear un código en RStudio; las gráficas y resultados que se presentan enseguida fueron los más relevantes del análisis, sin embargo, si se quiere ver todo lo que se hizo, en esta liga\footnote{\url{https://github.com/AnaLuisaMasetto/Estancia_de_Investigacion/tree/master/Analisis_Exploratorio_De_Datos} }se puede consultar el código completo.

En primer lugar, se presenta una tabla donde se identifican los valores únicos dentro de las variables de: __Punto de venta, sku, marca, gamma, zona, estado y ciudad, es decir, se identifican los distintos puntos de venta, productos, marcas, gammas, zonas, estados y ciudades__ en las que se realizan ventas de productos de telefonía celular. Además, se menciona el rango de fecha que abarcan los datos. 


\begin{figure}[h]
\includegraphics{G12.jpg}
\centering
\caption{Valores que adoptan las variables de los datos.}
\end{figure}

A continuación, se hace un breve análisis sobre el comportamiento de las ventas. El primer análisis que se hace es para observar como se comportan las ventas a nivel general de la compañia ABCD dependiendo del mes; en la gráfica siguiente se puede observarque hay un incremento de ventas en los meses de noviembre y diciembre, seguido por una caida drástica en los 3 meses siguientes. También se puede observar que la linea de regresión que fue incluida en la gráfica tiene pendiente negativa, lo cuál podría indicr que las ventas en general han estado disminuyendo.

\pagebreak

\begin{figure}[h]
\includegraphics{G13.jpg}
\centering
\end{figure}
 
El siguiente análisis se hace con respecto a las diferentes divisiones geográficas que se tienen en los datos. Con estas representaciones gráfica se puede observar que las 3 zonas con mayor número de venta en los 10 meses de registro son: __Centro sur con 512,223 ventas (48.85% de las ventas totales), centro occidente con 167,655 ventas (15.99%) y noroeste con 85,779 ventas (8.18%)__; las zonas con menos ventas registradas en los 10 meses de registro son: __Golfo de México (6.31%), Península de Yucatán(4.18%) y Pacífico Sur (2.67%)__. De la misma manera, se puede observar que de los 32 estados de la República Mexicana, __la ciudad de México, el estado de México y Jalisco__ son los estados con mayor número de ventas en los 10 meses de reegistro con __207,187__, __174,189__ y __71,879__ unidades vendidas respectivamente; Y los estados con menor número de ventas son: __Durango, Baja California Sur y Zacatecas__, con __5,213__, __4,781__, y __4,633__ unidades vendidas respectivamente. 

\begin{figure}[h]
\includegraphics{G14.jpg}
\centering
\end{figure}

\begin{figure}[h]
\includegraphics{G15.jpg}
\centering
\caption{Ventas registradas por zona geográfica y estado en los 10 meses de registro.}
\end{figure}

Una vez que se tiene esta información a nivel general y geográfico, se puede determinar cuál es contexto de las ventas con respecto a las marcas que maneja la compañía ABCD. Con la siguiente gráfica se puede observar que la marca que ha tenido mayor número de ventas en los 10 meses de registro fue: __Huawei__ con 408,179 unidades vendidas, seguido por Motorola y Samsung con 305,979 y 156,017 unidades vendidas respectivamente. También se puede observar que Sony, Affix y Lenovo son las marcas con menor número de unidades vendidas ya que juntas abarcan menos del 1% de las ventas totales registradas en los 10 meses. 

\begin{figure}[h]
\includegraphics{G16.jpg}
\centering
\caption{Ventas registradas por marca en los 10 meses de registro.}
\end{figure}

Como análisis adicional se genera la siguiente gráfica donde se muestra el comportamiento mensual de cada una de las marcas, los cuáles claramente difieren no únicamente en volumen de unidades vendidas, sino en su temporalidad. 

\begin{figure}[h]
\includegraphics{G17.jpg}
\centering
\caption{Comportamiento de las ventas por mes dependiendo de cada marca.}
\end{figure}

Finalmente, se hacen dos gráficas, donde la primera plasma las ventas que se tienen de cada marca en cada estado, con lo cual se puede observar que no todos los estados compran la misma cantidad de los mismos productos. Mientras que lal segunda gráfica plasma que el comportamiento de las ventas por estado y por marca también difieren en el tiempo. 

\pagebreak

\begin{figure}[h]
\includegraphics{G18.jpg}
\centering
\caption{Ventas registradas por marca y estado.}
\end{figure}

\begin{figure}[h]
\includegraphics{G19.jpg}
\centering
\caption{Ventas registradas por marca, estado y mes.}
\end{figure}



Con este breve análisis lo más notorio que se puede recalcar es que las ventas tienen un comportamiento dinámico, es decir, que cambian respecto al tiempo, lo cual invita a suponer que cada punto de venta requiere de diferentes cantidades y tipos de productos mensualmente. Gracias a este análsis exploratio fue más claro entender el porqué la compañía ABCD tiene la problemática de cómo construir sus portafolios de telefonía celular. 






\pagebreak

# Ingeniería de Características

Con una idea bien establecida del escenario general en el que se encuentra la compañía __ABCD__, se puede comenzar a tratar de crear más caracteristicas a partir de las que se tienen con el fin de mejorar la eficacia predictiva de los algoritmos propuestos en la siguiente la sección. Dichos algoritmos buscan cumplir con el objetivo del proyecto que es __mejorar la construcción de portafolios de productos de telefonía celular de la compañía ABCD__ donde lo que se busca predecir es __la cantidad de unidades de producto que se van a vender en cada punto de venta al siguiente mes de análisis__. Para ello y dado lo planteado se lleva a cado el siguiente proceso; al igual que en las secciones pasadas, lo plasmado en este documento es la información resumida, si se quiere ver a detalle el código para ejecutar lo siguiente se puede revisar esta liga \footnote{\url{https://github.com/AnaLuisaMasetto/Estancia_de_Investigacion/tree/master/Transformacion_De_Datos_E_Ingenieria_De_Caracteristicas} }. 

- \textbf{Construcción de índices:} Para comenzar y para facilitar el uso de variables categóricas dentro de los algoritmos, se crean índices para las variables: __punto de venta__, __sku__, __marca__, __gamma__, y __fecha__. 

\begin{figure}[h]
\includegraphics{G20.jpg}
\centering
\caption{Índices para variables categóricas.}
\end{figure}
- \textbf{Agrupación:} Se hace una agrupación por __punto de venta__, __sku__, __marca__, __gamma__, y __fecha__, para calcular el número total de ventas relacionadas con estas caracteristicas, es decir, construir la variable que se quiere predecir más adelante (__número de unidades a vender al siguiente mes__).

- \textbf{Completar serie de tiempo:} Con la agrupación anterior se puede observar que la serie de tiempo no esta completa, es decir, hay bloques de meses (0-9) e indices de productos que no aparecen en todos los puntos de venta, por lo tanto, esto se debe de completar. 

    - \textbf{} Lo primero que se hace es obtener las combinaciones existentes entre __punto de venta__, __sku__ y __bloque de fecha__, únicamente estas tres variables son consideradas para obtener el número total de combinaciones dado que cada sku tiene asociado únicamente una __gamma__ y una __marca__. El número total de combinaciones y de registros de la serie de tiempo completa es: 8,685,950. 
 
    - \textbf{} A continuación se relacionan los valores obtenidos en la agrupación con la serie de tiempo y los valores nulos significan que no hubo ventas registradas con esas caracteristicas ( __punto de venta__, __sku__, __marca__, __gamma__, y __fecha__). 
  
Apartir de este punto, la serie de tiempo ya esta completa, sin embargo, para enriquecer los modelos propuestos se hacen conteos y promedios por duplas de caracteristicas, esto con el fin de recopilar información adicional. 

- \textbf{Conteos por grupo:} Se sacan conteos y promedios de 4 duplas de caracteristicas:
    - \textbf{}Ventas promedio por tienda por mes.
    - \textbf{}Ventas promedio por marca por mes.
    - \textbf{}Ventas promedio por gamma por mes.
    - \textbf{}Ventas promedio por producto por mes. 
    
    - \textbf{}Ventas totales por tienda por mes. 
    - \textbf{}Ventas totales por marca por mes. 
    - \textbf{}Ventas totales por gamma por mes. 
    - \textbf{}Ventas totales por producto por mes.

- \textbf{Rezagos a tres tiempos :} La variables anteriores no pueden emplearse en un modelo dado que al momento de querer hacer la predicción para el mes siguiente (10 en este caso), no se va a tener información sobre cuántas ventas promedio por tienda se tuvieron ese mes ya que es algo que aún no pasa, por lo tanto, se opta por crear rezagos a 3 tiempos (1 mes, 2 meses y 3 meses) para contar con información del pasado para hacer las predicciónes. 
    - \textbf{}Por ejemplo, para el mes 10 se van a tener como variables adicionales: Ventas promedio por tienda del mes 9, ventas promedio por tienda del mes 8, ventas promedio por tienda del mes 7, y así sucesivamente con los demás conteos. 

Finalmente se tiene el archivo a ocupar con los modelos donde se consideran: 30 Variables y 8,685,950 registros. 

\pagebreak


\begin{figure}[h]
\includegraphics{G21.jpg}
\centering
\caption{Variables a considerar en la sección de modelado.}
\end{figure}






\pagebreak


# Modelos

Para realizar esta parte del proyecto y cumplir con el objetivo de este, se propusieron 3 modelos de regresión: __árboles de decisión__, __bosques aleatorios__ y __XGBoost__. Los tres modelos utilizan el mismo conjunto de datos limpios, transformados y con ingeniería de caractéristicas. 

Es importante mencionar que para llevar a cabo esta parte del proyecto, cada modelo fue desarrollado en un jupyter notebook los cuales se pueden consultar en esta liga\footnote{\url{https://github.com/AnaLuisaMasetto/Estancia_de_Investigacion/tree/master/Modelado} }. 

## Planteamiento del problema 

Dado que los modelos que se proponen son modelos de aprendizaje de máquina, es importante definir brevemente qué es el aprendizaje de máquina. Aprendizaje de máquina son métodos computacionales para aprender de los datos con el fin de mejorar el desempeño de una tarea\footnote{\url{https://felipegonzalez.github.io/aprendizaje-maquina-mcd-2018/introduccion.html} }. 

En este proyecto se tiene un problema que requiere de modelos de aprendizaje supervisado, es decir, modelos que tienen como tarea predecir o estimar una variable respuesta a partir de ciertos datos de entrada, también se clasifica como un problema de regresión dado que la variable respuesta es de valores continuos y no de asignación de clase (clasificación). 

Ya que se definió que el problema al que se enfrenta la compañía __ABCD__ es un problema de regresión que requiere de modelos de aprendizaje supervisado, se procede a identificar las partes que se requieren para estructurar un modelo. 

En primer lugar, se debe de definir la variable respuesta $Y$, en el caso de la construcción de portafolios de telefonía celular de la compañia ABCD, la variable respuesta $Y$ es __Ventas totales por tienda, mes y producto__. Seguido, hay que definir cuáles serán los datos de entrada que permitirán que los modelos aprendan, en este caso se cuenta con 29 variables independientes de las cuales 24 son rezagos de conteos y promedios, y las otras 5 son variables categóricas que ayudan a identificar ciertas características de cada producto vendido. 

Como siguiente paso al planteamiento del problema, es necesario definir las métricas a las cuáles se van a someter los modelos y así poder ser comparables unos con otros y llegar a un consenso final sobre el modelo con el mejor desempeño. 

##Métricas

Antes de comenzar con los modelos, es necesario definir el tipo de métricas que se necesitan para comparar los modelos. Para este proyecto se seleccionan 3 métricas, las cuales son de las más comunes a emplear cuando se trata de medirla precisión de modelos de regresión cuya variable respuesta es continua: 

- \textbf{Error Absoluto Medio:} Mide el promedio de la magnitud de los errores en un conjunto de predicciones. 
- \textbf{Raíz del Error Cuadrático Medio:} Muy parecido al error absoluto medio, esta métrica permite medir la magnitud del error con la diferencia de que esta métrica tiene la particularidad de dar mayor peso a errores más grandes.
- \textbf{Error Cuadrático Medio:} Al igual que la raíz error cuadrático medio, esta métrica mide la magnitud del error de predicción, sin embargo, las unidades de esta métrica terminan siendo cuadráticas, por ende, su interpretación no es tan fácil. 
   
En el contexto del proyecto, lo que se busca es encontrar el modelo que tenga el mejor desempeño con relación a estas métricas, es decir, el modelo cuyas métricas sean las menores. 

##Estructura de los modelos

Ya que se definió en su totalidad como va a estar estructurada la problematica, se procede a construir los modelos; y aunque cada modelo tiene sus implicaciones particulares (como formato en el que se ingestan los datos), los tres modelos se dividen de la siguiente manera: 

- \textbf{Parte 1: Lectura de los Datos:}
    - \textbf{}Los datos se cargan a un proyecto en __Watson Studio__ y en esa misma plataforma se crea el jupyter notebook donde se incertan las credenciales apropiadas para extraer los datos del depósito de objetos (object storage). 
    
- \textbf{Parte 2: División de los Datos en Entrenamiento y Prueba:}
    - \textbf{}Ya que los datos se hayan leido adecuadamente, se procede a dividir estos en dos conjuntos. El conjunto de entrenamiento que abarca los registros correspondientes a los bloques de fecha: __0,1,2,3,4,5,6,7,y 8__ con un total de __7,817,355__ observaciones, y el conjunto de prueba abarca únicamente los registros del bloque de fecha: __9__ con un total de __868,595__ observaciones. 
    
- \textbf{Parte 3: construcción del modelo:}
    - \textbf{} Una vez que los datos ya se dividieron en conjunto de entrenamiento y prueba, se continua con la construcción de cada uno de los modelos. Más adelante se especifica lo que fue necesario para ejecutar cada modelo, sin embargo, en este punto se describen las caracteristicas generales que se tuvieron que tomar en cuenta para la construcción de cada modelo. 
    - \textbf{Aplicar validación cruzada para series de tiempo:} 
      - \textbf{}Se sabe que validación cruzada es una técnica popular para evaluar los resultados de un modelo, particionando el conjunto de entrenamiento en: entrenamiento y validación para después calcular la media  de las medidas de evaluación sobre las diversas particiones. Una de las principales razones para usar validación cruzada es que no se tienen los suficientes datos para el conjunto de entrenamiento y prueba, y como no se quiere tener sobreajuste, las particiones que hace validación cruzada son muy útiles. Sin embargo, cuando se trata de un problema de series de tiempo donde existe dependencia temporal, la tarea se vuelve un poco más compleja ya que las particiones deben de respetar la cronología de los eventos dentro de las observaciones. 
    - \textbf{Aplicar un GridSearch:} Uno de los factores más importantes a considerar cuando se están construyendo modelos de aprendizaje de máquina es que el ajuste y la afinación de parámetros. Es por eso que cada uno de los modelos propuestos utilizan diversas combinaciones de parámetros con el fin de encontrar el que mejor se desempeñe. 
    - \textbf{Entrenamiento y Evaluación del modelo con los diferentes parámetros propuestos:} Como ya se mencionó en el punto anterior, de los tres modelos propuestos cada uno se construyen con diversos parámetros. En total cada modelo tiene 8 combinaciones de parámetros que se utilizan para entrenar 8 modelos y de estos se obtienen las métricas mencionadas con anterioridad. 
    - \textbf{Selección del mejor conjunto de parámetros:} Ya que se tienen las puntuaciones de los modelos con respecto a sus metricas de error, se selecciona el modelo cuyos errores tienen el menor valor. 
    - \textbf{Reentrenamiento con los parámetros que obtuvieron el mejor desempeño:} Una vez que el mejor modelo ya fue seleccionado, este se reentrena con los parámetros con el mejor desempeño para después utilizarse con el conjunto de prueba. 
    - \textbf{Evaluación del mejor modelo con el conjunto de prueba: }Ya que el modelo fue entrenado con los mejores parámetros obtenidos, se utiliza el modelo con el conjunto de datos para ver el resultado que obtiene el modelo con un conjunto de datos nuevo. 
    
Finalmente, se comparan los resultados con el conjunto de prueba de los 3 modelos y se selecciona el mejor como solución para la problemática de la compañía ABCD. 

Ya que se definió la estructura que siguen los modelos y las caracteristicas importantes a tomar en cuenta, a continuación se presentan cada uno de los modelos con sus respectivos resultados. 

## Árbol de Decisión 

El primer modelo que se propuso fue un __árbol de decisión (decision tree)__. Para construir este modelo fue necesario aplicar validación cruzada para series de tiempo con 3 particiones y en seguida se definió un GridSearch donde los parámetros a cambiar fueron:

- \textbf{Max Depth:} Profundidad máxima del árbol. Para este problema de consideraron dos valores: $[2,5]$.
- \textbf{Valor mínimo de muestra:} El valor mínimo de muestras requeridas para particionar un nodo interno. Para este problema se probaron también 2 valores distintos: $[2,10]$.
- \textbf{Max leaf node}De la misma manera, se probaron dos valores distintos: $[3,10]$. 

Con estos diferentes parámetros se tiene como resultado un total de 8 modelos a probar para determinar la combinación que de el mejor resultado con respecto a las métricas requeridas (MAE, MSE y RMSE). Los resultados después de entrenar estos 8 modelos fueron: 

\begin{figure}[h]
\includegraphics{G22.jpg}
\centering
\caption{Resultados del GridSearch con el conjunto de entrenamiento.}
\end{figure}

Con la tabla anterior se puede observar que el mejor modelo es el número __6__ con parámetros __max_depth: 5__, __min_samples_split: 2__, y __max_leaf_nodes: 10__. Estos parámetros se seleccionan y se vuelve a entrenar el modelo ahora con estos valores. Una vez que se ya se reentrenó el modelo con los parámetros que dieron el mejor resultado con el conjunto de entrenamiento, se prueba el modelo ahora con el conjunto de prueba. Los resultados que se obtuvieron fueron: 

\begin{figure}[h]
\includegraphics{G23.jpg}
\centering
\caption{Resultados del mejor árbol de decisión con el conjunto de prueba.}
\end{figure}

Este modelo con sus respectivos resultados es el que se va a comparar con los demás para así determinar cuál fue el que dio mejor resultado. 

\pagebreak


## Bosque Aleatorio

El siguiente modelo que se propuso fue un __bosque aleatorio (random forest)__. Al igual que el modelo anterior, fue necesario aplicar validación cruzada para series de tiempo con 3 particiones con el fin de evitar sobreajuste. En seguida se definió un GridSearch donde los parámetros a cambiar fueron:

- \textbf{Profundidad máxima:}Profundidad máxima del árbol. Para este problema de consideraron dos valores: $[2,9]$.
- \textbf{Valor mínimo de muestra:} El valor mínimo de muestras requeridas para particionar un nodo interno. Para este problema se probaron también 2 valores distintos: $[8,10]$.
- \textbf{n estimator:} Número de árboles en el bosque. De la misma manera, se probaron dos valores distintos: $[2,3]$$. 

Con estos diferentes parámetros se tiene como resultado un total de 8 modelos a probar para determinar la combinación que de el mejor resultado con respecto a las métricas requeridas (MAE, MSE y RMSE). Los resultados después de entrenar estos 8 modelos fueron: 

\begin{figure}[h]
\includegraphics{G24.jpg}
\centering
\caption{Resultados del GridSearch con el conjunto de entrenamiento.}
\end{figure}

Con la tabla anterior se puede observar que el mejor modelo es el número __5__ con parámetros __max_depth: 9__, __min_samples_split: 8__, y __n_estimators: 3__. Estos parámetros se seleccionan y se utilizan para volver a entrenar el modelo (random forest regressor) ahora con estos valores. Una vez que se ya se reentrenó el modelo con los parámetros que dieron el mejor resultado con el conjunto de entrenamiento, se prueba el modelo ahora con el conjunto de prueba. Los resultados que se obtuvieron fueron:

\begin{figure}[h]
\includegraphics{G25.jpg}
\centering
\caption{Resultados del mejor bosque aleatorio con el conjunto de prueba.}
\end{figure}

Este modelo con sus respectivos resultados es el que se va a comparar con los demás para así determinar cuál fue el que dio mejor resultado.

\pagebreak

## Extreme Gradient Boosting (XGBoost)

El último modelo que se propuso fue un __Extreme Gradient Boosting (XGBoost)__. Al igual que los modelos anteriores, fue necesario aplicar validación cruzada para series de tiempo con 3 particiones con el fin de evitar sobreajuste. En seguida se definió un GridSearch donde los parámetros a cambiar fueron:

- \textbf{Profundidad máxima:}Profundidad máxima del árbol. Para este problema de consideraron dos valores: $[2,3]$.
- \textbf{Tasa de aprendizaje:} $[0.0003, 0.003]$.
- \textbf{n estimator:} Número de árboles. De la misma manera, se probaron dos valores distintos: $[2,3]$. 

Con estos diferentes parámetros se tiene como resultado un total de 8 modelos a probar para determinar la combinación que de el mejor resultado con respecto a las métricas requeridas (MAE, MSE y RMSE). Los resultados después de entrenar estos 8 modelos fueron: 

\begin{figure}[h]
\includegraphics{G26.jpg}
\centering
\caption{Resultados del GridSearch con el conjunto de entrenamiento.}
\end{figure}

Con la tabla anterior se puede observar que el mejor modelo es el número __7__ con parámetros __max_depth: 3__, __learning rate: 0.003__, y __n_estimators: 3__. Estos parámetros se seleccionan y se utilizan para volver a entrenar el modelo (xgboost regressor) ahora con estos valores. Una vez que se ya se reentrenó el modelo con los parámetros que dieron el mejor resultado con el conjunto de entrenamiento, se prueba el modelo ahora con el conjunto de prueba. Los resultados que se obtuvieron fueron:

\begin{figure}[h]
\includegraphics{G27.jpg}
\centering
\caption{Resultados del mejor XGBoost con el conjunto de prueba.}
\end{figure}

Este modelo con sus respectivos resultados es el que se va a comparar con los demás para así determinar cuál fue el que dio mejor resultado.

\pagebreak

## Modelo seleccionado

Tras correr los 24 modelos anteriores, se observa en la siguiente tabla el mejor de cada tipo de modelo. De esto se concluye que el mejor modelo que fue construido fue el XGBoos, ya que de todos, este fue el que tuvo mejor desempeño en tanto a las 3 métricas. Este fue el modelo que al final se propuso como solución a la compañía ABCD. 

\begin{figure}[h]
\includegraphics{G28.jpg}
\centering
\end{figure}

\pagebreak

# Conclusiones

Este trabajo abarca desde la limpieza de datos hasta el despliegue de resultados de modelos propuestos para ayudar a la compañía ABCD a resolver su problema sobre contrucción de portafoliso de telefonía celular. 

Desde un punto de vista productivo dentro de la empresa ABCD, es sorprendente que en estos tiempos, aún existan compañías cuyo sistema de manejo de demanda no haya sido actualizado o siquiera homogeneizado; no hubo mucha información proporcionada por la compañía ABCD, sin embargo, se sabe que esta no poseía un modelo particular para determinar las unidades de producto a vender en cada uno de sus puntos de venta. Dado los avances tecnológicos actuales en áreas como ciencia de datos y aprendizaje de máquina, es de suma importancia que las empresas empiecen a familiarizarse con estos y así seguir manteniendo un nivel competitivo. 

Desde un punto de vista académico, es cierto que dentro de un proyecto de ciencia de datos, la mayor parte del tiempo invertido será en la limpieza de datos; el mayor reto en este proyecto con respecto a la limpieza fue que la infromación faltante debía completarse mediante un proceso sumamente artesanal o la infromación extra que fue brindada no tenía un significado preciso dado la falta de un diccionario que explicara lo que abarcaba cada uno de los registros adicionales. 

Otro aspecto importante a resaltar, es que herramientas existen para explotar los datos, sin embargo, no todos saben cómo o en qué contexto aplicarlas. Construir los modelos de aprendizaje de máquina fue más fácil desde un código en jupyter notebook, mientras que la limpieza y el procesamiento de los datos se realizó en un código en RStudio. 

En forma de resumen, este proyecto presenta la limpieza de datos, su transformación, análIsis exploratorio, ingeniería de caracterÍsticas y modelado. En el proyecto se presentan 3 tipos de modelos de aprendizaje de máquina supervisado para una tarea de regresión. El primero fue un árbol de decisión, seguido por un bosque aleatorio y finalmente un XGBoost. Cada modelo fue provado con diferentes parámetros y, por lo tanto, fueron 24 los modelos que se corrieron en total para llevar a cabo este proyecto.El mejor modelo fue un XGBoost que permite cumplir con el objetivo general de este proyecto que es ayudar a la compañía ABCD a construir sus protafolios de telefonía celular para sus diversos puntos de venta. 

Como conclusión, el desarrollo de un proyecto de ciencia de datos requiere de tiempo y suma atención a los detalles. El uso adecuado de estos modelos puede traer consigo un gran número de ventajas; para este caso en particular, el tener un modelo que permita construir los portafolios de la compañia ABCD puede traer consigo un mejor manejo de inventarios, por ende una reducción en costo de almacenamiento y transporte, también puede haber menor deserción de clientes dado que los productos se encuentran donde se requieren, sin embargo, esto no se puede cunatificar en este momento. 

Finalmente, el trabajo presente podría mejorarse si se agregan más variables que aporten más información al modelo ya sean proporcionadas por la compañía ABCD, o por variables externas que puedan tener un impacto en las ventas de esta. 

# Código

Si se desean consultar los códigos que se hicieron para llevar acabo este proyecto, estos se encuentran el esta liga\footnote{\url{https://github.com/AnaLuisaMasetto/Estancia_de_Investigacion} }.

\pagebreak

# Bibliografía

Aler, R. (2015). DECISION TREE HYPER-PARAMETERS. TUNING DECISION TREES. 26 de septiembre de 2019, de Universidad Carlos III de Madrid Sitio web: \url{http://ocw.uc3m.es/ingenieria-informatica/machine-learning-i/decisiontreeshyperparameters.html}

González, L. (2018). ¿Qué es aprendizaje de máquina (machine learning)?. 26 de septiembre de 109, de Github Sitio web: 
\url{https://felipegonzalez.github.io/aprendizaje-maquina-mcd-2018/introduccion.html}

Handika, T. (2017). Practicing Regression Techniques on House Prices Dataset-Part 2. 26 de septiembre de 2019, de Media Sitio web: 
\url{https://medium.com/@blazetamareborn/practicing-regression-techniques-on-house-prices-dataset-part2-16a78eec0df9}

Kaghazgarian, M. (2018). Decision Tree Regressor on Bike Sharing Dataset. 26 de Septiembre de 2016, de Kaggle Sitio web: 
\url{https://www.kaggle.com/marklvl/decision-tree-regressor-on-bike-sharing-dataset/comments}

Koehrsen, W. (2018). Hyperparameter Tuning the Random Forest in Python. 26 de septiembre 2019, de Medium Sitio web: 
\url{https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74}

Lemagnen, K. (2017). Hyperparameter tuning in XGBoost. 26 de septiembre de 2019, de Media Sitio web: 
\url{https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f}

Malik, U. (2018). Cross Validation and Grid Search for Model Selection in Python. 26 de septiembre de 2019, de Stackabuse Sitio web: 
\url{https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/}

Ruiz, D. (2018). predicting_sales_1c. 26 de septiembre de 2016, de Github Sitio web: https://github.com/Druizm128/predicting_sales_1c

Sammut, C. (2019). Mean Absolute Error. 26 de septiembre de 2019, de Springer Link Sitio web: 
\url{https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_525}

s.a. (2017). XGBRegressor vs. xgboost.train huge speed difference?. 26 de septiembre de 2019, de Stackexchange Sitio web: https://datascience.stackexchange.com/questions/17282/xgbregressor-vs-xgboost-train-huge-speed-difference

s.a. (2016). MAE and RMSE — Which Metric is Better?. 26 de septiembre de 2019, de Media Sitio web: 
\url{https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d}

s.a. (2019). XGBoost Parameters. 26 de septiembre de 2019, de XGBOOST Sitio web: 
\url{https://xgboost.readthedocs.io/en/latest/parameter.html}

s.a. (2019). COMUNICADO DE PRENSA NÚM. 179/19. 26 de septiembre de 2019, de INEGI Sitio web: \url{https://www.inegi.org.mx/contenidos/saladeprensa/boletines/2019/OtrTemEcon/ENDUTIH_2018.pdf}

scikit-learn developers. (2019). Decision Tree Regression. 26 de septiembre de 2019, de scikit-learn Sitio web: 
\url{https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html#sphx-glr-auto-examples-tree-plot-tree-regression-py}

scikit-learn developers. (2019). sklearn.tree.DecisionTreeRegressor. 26 de septiembre de 2019, de scikit-learn Sitio web: 
\url{https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html}





